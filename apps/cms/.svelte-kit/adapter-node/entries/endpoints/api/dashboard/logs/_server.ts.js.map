{"version":3,"file":"_server.ts.js","sources":["../../../../../../../../src/routes/api/dashboard/logs/+server.ts"],"sourcesContent":["/**\n * @file src/routes/api/dashboard/logs/+server.ts\n * @description Optimized API endpoint for system logs with Reverse Reading and ANSI support.\n *\n * @example GET /api/dashboard/logs?limit=20&level=all&search=&page=1\n *\n * Features:\n * - **Secure Authorization:** Access is controlled centrally by `src/hooks.server.ts`.\n * - **Reverse Reading:** Reads plaintext logs from the end of the file (newest first).\n * - **Early Exit:** Stops processing files once the requested page/limit is satisfied.\n * - **Memory Efficient:** No longer loads entire files into RAM.\n */\n\nimport { publicEnv } from '@shared/stores/globalSettings.svelte';\nimport { error, json } from '@sveltejs/kit';\nimport { createReadStream } from 'node:fs';\nimport { open, readdir, stat } from 'node:fs/promises';\nimport { join } from 'node:path';\nimport { createInterface } from 'node:readline';\nimport { createBrotliDecompress, createGunzip } from 'node:zlib';\nimport type { RequestHandler } from './$types';\n\n// System Logger\nimport { logger } from '@shared/utils/logger.server';\nimport type { ISODateString } from '@cms-types';\n\n// Validation\nimport * as v from 'valibot';\n\nconst QuerySchema = v.object({\n\tlevel: v.optional(v.string(), 'all'),\n\tsearch: v.optional(v.string(), ''),\n\tstartDate: v.optional(v.string()),\n\tendDate: v.optional(v.string()),\n\tpage: v.optional(v.pipe(v.number(), v.minValue(1)), 1),\n\tlimit: v.optional(v.pipe(v.number(), v.minValue(1), v.maxValue(100)), 20)\n});\n\nconst LogEntrySchema = v.object({\n\ttimestamp: v.string(),\n\tlevel: v.string(),\n\tmessage: v.string(),\n\tmessageHtml: v.string(),\n\targs: v.array(v.unknown())\n});\n\n// ANSI color code mappings to CSS colors\nconst ANSI_COLOR_MAP: Record<string, string> = {\n\t'30': '#000000', // black\n\t'31': '#dc2626', // red\n\t'32': '#16a34a', // green\n\t'33': '#ca8a04', // yellow\n\t'34': '#2563eb', // blue\n\t'35': '#9333ea', // magenta\n\t'36': '#0891b2', // cyan\n\t'37': '#374151', // white/gray\n\t'90': '#6b7280', // bright black/gray\n\t'91': '#ef4444', // bright red\n\t'92': '#22c55e', // bright green\n\t'93': '#eab308', // bright yellow\n\t'94': '#3b82f6', // bright blue\n\t'95': '#a855f7', // bright magenta\n\t'96': '#06b6d4', // bright cyan\n\t'97': '#f9fafb' // bright white\n};\n\ninterface RawLogEntry {\n\ttimestamp: ISODateString;\n\tlevel: string;\n\tmessage: string;\n\tmessageHtml: string;\n\targs: unknown[];\n}\n\n// --- ANSI & Parsing Logic (Kept identical to original) ---\n\nfunction convertAnsiToHtml(text: string): string {\n\tlet result = '';\n\tlet currentPos = 0;\n\tconst openTags: string[] = [];\n\tconst ansiRegex = /\\[(\\d+)m/g;\n\tlet match;\n\n\twhile ((match = ansiRegex.exec(text)) !== null) {\n\t\tresult += text.substring(currentPos, match.index);\n\t\tconst code = match[1];\n\n\t\tif (code === '0') {\n\t\t\twhile (openTags.length > 0) {\n\t\t\t\tresult += '</span>';\n\t\t\t\topenTags.pop();\n\t\t\t}\n\t\t} else {\n\t\t\tconst color = ANSI_COLOR_MAP[code];\n\t\t\tif (color) {\n\t\t\t\tconst isBold = ['1', '91', '92', '93', '94', '95', '96', '97'].includes(code);\n\t\t\t\tresult += `<span style=\"color: ${color}; font-weight: ${isBold ? 'bold' : 'normal'};\">`;\n\t\t\t\topenTags.push('color');\n\t\t\t} else if (code === '1') {\n\t\t\t\tresult += '<span style=\"font-weight: bold;\">';\n\t\t\t\topenTags.push('bold');\n\t\t\t} else if (code === '4') {\n\t\t\t\tresult += '<span style=\"text-decoration: underline;\">';\n\t\t\t\topenTags.push('underline');\n\t\t\t}\n\t\t}\n\t\tcurrentPos = match.index + match[0].length;\n\t}\n\tresult += text.substring(currentPos);\n\twhile (openTags.length > 0) {\n\t\tresult += '</span>';\n\t\topenTags.pop();\n\t}\n\treturn result;\n}\n\nconst parseLogLineWithColors = (line: string): RawLogEntry | null => {\n\tconst regex = /^(\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.\\d{3}Z)\\s+\\[([^\\]]+)\\]\\s+(.*)$/;\n\tconst match = line.match(regex);\n\n\tif (!match) {\n\t\t// Fallback parsing\n\t\tconst simpleRegex = /^(\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.\\d{3}Z)?\\s*(?:\\[([^\\]]+)\\])?\\s*\\[([A-Z]+)\\](?::\\s*)?(.*)$/;\n\t\tconst simpleMatch = line.match(simpleRegex);\n\n\t\tif (simpleMatch) {\n\t\t\tconst [, timestamp, , level, message] = simpleMatch;\n\t\t\tconst cleanMessage = message || line;\n\t\t\treturn {\n\t\t\t\ttimestamp: (timestamp || new Date().toISOString()) as ISODateString,\n\t\t\t\tlevel: level || 'INFO',\n\t\t\t\tmessage: cleanMessage.replace(/\\[\\d+(?:;\\d+)*m/g, ''),\n\t\t\t\tmessageHtml: convertAnsiToHtml(cleanMessage),\n\t\t\t\targs: []\n\t\t\t};\n\t\t}\n\t\treturn {\n\t\t\ttimestamp: new Date().toISOString() as ISODateString,\n\t\t\tlevel: 'INFO',\n\t\t\tmessage: line.replace(/\\[\\d+(?:;\\d+)*m/g, ''),\n\t\t\tmessageHtml: convertAnsiToHtml(line),\n\t\t\targs: []\n\t\t};\n\t}\n\n\tconst [, timestamp, level, contentPart] = match;\n\tlet message = contentPart.trim();\n\tlet args: unknown[] = [];\n\n\tconst lastBracketIndex = message.lastIndexOf('[');\n\tif (lastBracketIndex > -1) {\n\t\tconst potentialJsonArgs = message.substring(lastBracketIndex);\n\t\ttry {\n\t\t\tconst parsedArgs = JSON.parse(potentialJsonArgs);\n\t\t\tif (Array.isArray(parsedArgs)) {\n\t\t\t\targs = parsedArgs;\n\t\t\t\tmessage = message.substring(0, lastBracketIndex).trim();\n\t\t\t}\n\t\t} catch {\n\t\t\t/* ignore */\n\t\t}\n\t}\n\n\treturn {\n\t\ttimestamp: timestamp as ISODateString,\n\t\tlevel,\n\t\tmessage: message.replace(/\\[\\d+(?:;\\d+)*m/g, ''),\n\t\tmessageHtml: convertAnsiToHtml(message),\n\t\targs\n\t};\n};\n\n// --- New Optimized Helper Functions ---\n\n/**\n * Reads a plain text file strictly backwards in chunks.\n * This is crucial for performance on \"Page 1\" of large log files.\n */\nasync function* readLinesReverse(filePath: string): AsyncGenerator<string> {\n\tconst fileHandle = await open(filePath, 'r');\n\ttry {\n\t\tconst stats = await fileHandle.stat();\n\t\tconst bufferSize = 64 * 1024; // 64KB chunks\n\t\tconst buffer = Buffer.alloc(bufferSize);\n\t\tlet position = stats.size;\n\t\tlet leftover = '';\n\n\t\twhile (position > 0) {\n\t\t\tconst readSize = Math.min(position, bufferSize);\n\t\t\tposition -= readSize;\n\n\t\t\tawait fileHandle.read(buffer, 0, readSize, position);\n\t\t\tconst chunk = buffer.toString('utf-8', 0, readSize);\n\t\t\tconst lines = (chunk + leftover).split('\\n');\n\n\t\t\t// The first element is the end of the line from the *previous* chunk (logically next line)\n\t\t\t// The last element is the start of the line from the *next* chunk (logically previous line)\n\t\t\tleftover = lines.shift() || '';\n\n\t\t\t// Iterate lines in reverse (they are currently in file order within the chunk)\n\t\t\tfor (let i = lines.length - 1; i >= 0; i--) {\n\t\t\t\tif (lines[i].trim()) yield lines[i];\n\t\t\t}\n\t\t}\n\n\t\tif (leftover.trim()) yield leftover;\n\t} finally {\n\t\tawait fileHandle.close();\n\t}\n}\n\n/**\n * Reads a compressed file stream forward.\n * Since we can't easily read compressed files backward, we read forward\n * but collect lines to return them in reverse order for that specific file.\n */\nasync function getCompressedLogLines(filePath: string, isBrotli: boolean): Promise<string[]> {\n\tconst lines: string[] = [];\n\tlet fileStream: NodeJS.ReadableStream = createReadStream(filePath);\n\n\tif (isBrotli) {\n\t\tfileStream = fileStream.pipe(createBrotliDecompress());\n\t} else {\n\t\tfileStream = fileStream.pipe(createGunzip());\n\t}\n\n\tconst rl = createInterface({\n\t\tinput: fileStream,\n\t\tcrlfDelay: Infinity\n\t});\n\n\tfor await (const line of rl) {\n\t\tif (line.trim()) lines.push(line);\n\t}\n\n\t// Reverse so the newest lines (at the bottom of the file) come first\n\treturn lines.reverse();\n}\n\nexport const GET: RequestHandler = async ({ locals, url }) => {\n\tconst { user } = locals;\n\n\ttry {\n\t\tif (!user) {\n\t\t\tthrow error(401, 'Unauthorized');\n\t\t}\n\n\t\tconst params = v.parse(QuerySchema, {\n\t\t\tlevel: url.searchParams.get('level') || undefined,\n\t\t\tsearch: url.searchParams.get('search') || undefined,\n\t\t\tstartDate: url.searchParams.get('startDate') || undefined,\n\t\t\tendDate: url.searchParams.get('endDate') || undefined,\n\t\t\tpage: Number(url.searchParams.get('page')) || undefined,\n\t\t\tlimit: Number(url.searchParams.get('limit')) || undefined\n\t\t});\n\n\t\tconst LOG_DIRECTORY = 'logs';\n\t\tconst LOG_FILE_NAME = 'app.log';\n\t\tconst LOG_RETENTION_DAYS = publicEnv.LOG_RETENTION_DAYS || 30;\n\n\t\tconst startDateTime = params.startDate ? new Date(params.startDate).getTime() : 0;\n\t\tconst endDateTime = params.endDate ? new Date(new Date(params.endDate).setHours(23, 59, 59, 999)).getTime() : Infinity;\n\n\t\t// Calculate how many logs we need to skip and take\n\t\tconst neededSkip = (params.page - 1) * params.limit;\n\t\tconst neededTake = params.limit;\n\t\tconst totalNeeded = neededSkip + neededTake;\n\n\t\tconst collectedLogs: RawLogEntry[] = [];\n\n\t\t// 1. Get Files and Sort Newest -> Oldest\n\t\tconst files = await readdir(LOG_DIRECTORY);\n\t\tconst logFiles = files\n\t\t\t.filter((file) => file === LOG_FILE_NAME || file.startsWith(`${LOG_FILE_NAME}.`))\n\t\t\t.sort((a, b) => {\n\t\t\t\t// Custom sort: app.log is always newest/first\n\t\t\t\tif (a === LOG_FILE_NAME) return -1;\n\t\t\t\tif (b === LOG_FILE_NAME) return 1;\n\t\t\t\t// Otherwise sort by string (usually app.log.1, app.log.2)\n\t\t\t\t// Assuming lower number = newer rotated log, or use mtime if needed\n\t\t\t\treturn a.localeCompare(b);\n\t\t\t});\n\n\t\t// 2. Process files until we have enough logs\n\t\t// Note: We iterate files Newest -> Oldest\n\t\tfor (const file of logFiles) {\n\t\t\t// Early exit if we have enough logs\n\t\t\tif (collectedLogs.length >= totalNeeded) break;\n\n\t\t\tconst filePath = join(LOG_DIRECTORY, file);\n\t\t\tconst fileStats = await stat(filePath);\n\n\t\t\t// Retention check\n\t\t\tconst isRotatedLog = file !== LOG_FILE_NAME;\n\t\t\tif (isRotatedLog && fileStats.mtimeMs < Date.now() - LOG_RETENTION_DAYS * 24 * 60 * 60 * 1000) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tconst isCompressed = file.endsWith('.gz') || file.endsWith('.br');\n\t\t\tconst isBrotli = file.endsWith('.br');\n\n\t\t\tlet linesGenerator: AsyncGenerator<string> | string[];\n\n\t\t\tif (isCompressed) {\n\t\t\t\t// Compressed files must be read fully to memory (unavoidable for stream), then reversed\n\t\t\t\tlinesGenerator = await getCompressedLogLines(filePath, isBrotli);\n\t\t\t} else {\n\t\t\t\t// Plain text: Read BACKWARD efficiently\n\t\t\t\tlinesGenerator = readLinesReverse(filePath);\n\t\t\t}\n\n\t\t\t// Iterate lines (which are now guaranteed to be Newest -> Oldest)\n\t\t\tfor await (const line of linesGenerator) {\n\t\t\t\t// Early exit loop\n\t\t\t\tif (collectedLogs.length >= totalNeeded) break;\n\n\t\t\t\t// Handle AsyncGenerator vs Array\n\t\t\t\tif (typeof line !== 'string') continue;\n\n\t\t\t\tconst entry = parseLogLineWithColors(line);\n\t\t\t\tif (!entry) continue;\n\n\t\t\t\tconst entryTimestamp = new Date(entry.timestamp).getTime();\n\n\t\t\t\t// Date Filter Optimization:\n\t\t\t\t// If we are reading Newest->Oldest, and we hit a log older than startDate,\n\t\t\t\t// we can theoretically stop EVERYTHING if we assume strict ordering.\n\t\t\t\t// However, async logging might not be strictly ordered to the millisecond, so we just filter.\n\t\t\t\t// But if it's WAY before, we could break. For safety, we just filter.\n\t\t\t\tif (entryTimestamp < startDateTime) continue; // Too old\n\t\t\t\tif (entryTimestamp > endDateTime) continue; // Too new (rare if reading reverse, but possible)\n\n\t\t\t\t// Level & Search Filter\n\t\t\t\tconst levelMatch = params.level === 'all' || entry.level.toLowerCase() === params.level.toLowerCase();\n\t\t\t\tconst textMatch = !params.search || entry.message.toLowerCase().includes(params.search.toLowerCase());\n\n\t\t\t\tif (levelMatch && textMatch) {\n\t\t\t\t\tcollectedLogs.push(entry);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// 3. Slice the specific page\n\t\t// We might have collected slightly more than needed due to loop logic, so we slice exactly.\n\t\t// Since we collected in Newest->Oldest order, index 0 is the newest log.\n\t\tconst paginatedLogs = collectedLogs.slice(neededSkip, neededSkip + neededTake);\n\n\t\tconst validatedLogs = v.parse(v.array(LogEntrySchema), paginatedLogs);\n\n\t\tlogger.info('Logs fetched (Optimized)', {\n\t\t\tcount: paginatedLogs.length,\n\t\t\tpage: params.page,\n\t\t\trequestedBy: user._id\n\t\t});\n\n\t\treturn json({\n\t\t\tlogs: validatedLogs,\n\t\t\t// Note: Total count is now approximate or limited because we didn't read all files.\n\t\t\t// For infinite scrolling/pagination, we usually return \"hasMore\" or just the length.\n\t\t\t// If specific total is needed, we'd have to scan everything, which defeats optimization.\n\t\t\t// We return collectedLogs.length as a proxy for \"logs found so far\".\n\t\t\ttotal: collectedLogs.length,\n\t\t\tpage: params.page,\n\t\t\tlimit: params.limit,\n\t\t\t// If we filled the buffer, assume there might be more pages.\n\t\t\thasMore: collectedLogs.length >= totalNeeded\n\t\t});\n\t} catch (err) {\n\t\tif (err instanceof v.ValiError) {\n\t\t\tthrow error(400, 'Invalid request parameters');\n\t\t}\n\t\tlogger.error('Error fetching logs:', err);\n\t\tthrow error(500, 'Failed to fetch logs');\n\t}\n};\n"],"names":["timestamp","level","message"],"mappings":";;;;;;;;;AA6BA,MAAM,cAAc,EAAE,OAAO;AAAA,EAC5B,OAAO,EAAE,SAAS,EAAE,OAAA,GAAU,KAAK;AAAA,EACnC,QAAQ,EAAE,SAAS,EAAE,OAAA,GAAU,EAAE;AAAA,EACjC,WAAW,EAAE,SAAS,EAAE,QAAQ;AAAA,EAChC,SAAS,EAAE,SAAS,EAAE,QAAQ;AAAA,EAC9B,MAAM,EAAE,SAAS,EAAE,KAAK,EAAE,OAAA,GAAU,EAAE,SAAS,CAAC,CAAC,GAAG,CAAC;AAAA,EACrD,OAAO,EAAE,SAAS,EAAE,KAAK,EAAE,OAAA,GAAU,EAAE,SAAS,CAAC,GAAG,EAAE,SAAS,GAAG,CAAC,GAAG,EAAE;AACzE,CAAC;AAED,MAAM,iBAAiB,EAAE,OAAO;AAAA,EAC/B,WAAW,EAAE,OAAA;AAAA,EACb,OAAO,EAAE,OAAA;AAAA,EACT,SAAS,EAAE,OAAA;AAAA,EACX,aAAa,EAAE,OAAA;AAAA,EACf,MAAM,EAAE,MAAM,EAAE,SAAS;AAC1B,CAAC;AAGD,MAAM,iBAAyC;AAAA,EAC9C,MAAM;AAAA;AAAA,EACN,MAAM;AAAA;AAAA,EACN,MAAM;AAAA;AAAA,EACN,MAAM;AAAA;AAAA,EACN,MAAM;AAAA;AAAA,EACN,MAAM;AAAA;AAAA,EACN,MAAM;AAAA;AAAA,EACN,MAAM;AAAA;AAAA,EACN,MAAM;AAAA;AAAA,EACN,MAAM;AAAA;AAAA,EACN,MAAM;AAAA;AAAA,EACN,MAAM;AAAA;AAAA,EACN,MAAM;AAAA;AAAA,EACN,MAAM;AAAA;AAAA,EACN,MAAM;AAAA;AAAA,EACN,MAAM;AAAA;AACP;AAYA,SAAS,kBAAkB,MAAsB;AAChD,MAAI,SAAS;AACb,MAAI,aAAa;AACjB,QAAM,WAAqB,CAAA;AAC3B,QAAM,YAAY;AAClB,MAAI;AAEJ,UAAQ,QAAQ,UAAU,KAAK,IAAI,OAAO,MAAM;AAC/C,cAAU,KAAK,UAAU,YAAY,MAAM,KAAK;AAChD,UAAM,OAAO,MAAM,CAAC;AAEpB,QAAI,SAAS,KAAK;AACjB,aAAO,SAAS,SAAS,GAAG;AAC3B,kBAAU;AACV,iBAAS,IAAA;AAAA,MACV;AAAA,IACD,OAAO;AACN,YAAM,QAAQ,eAAe,IAAI;AACjC,UAAI,OAAO;AACV,cAAM,SAAS,CAAC,KAAK,MAAM,MAAM,MAAM,MAAM,MAAM,MAAM,IAAI,EAAE,SAAS,IAAI;AAC5E,kBAAU,uBAAuB,KAAK,kBAAkB,SAAS,SAAS,QAAQ;AAClF,iBAAS,KAAK,OAAO;AAAA,MACtB,WAAW,SAAS,KAAK;AACxB,kBAAU;AACV,iBAAS,KAAK,MAAM;AAAA,MACrB,WAAW,SAAS,KAAK;AACxB,kBAAU;AACV,iBAAS,KAAK,WAAW;AAAA,MAC1B;AAAA,IACD;AACA,iBAAa,MAAM,QAAQ,MAAM,CAAC,EAAE;AAAA,EACrC;AACA,YAAU,KAAK,UAAU,UAAU;AACnC,SAAO,SAAS,SAAS,GAAG;AAC3B,cAAU;AACV,aAAS,IAAA;AAAA,EACV;AACA,SAAO;AACR;AAEA,MAAM,yBAAyB,CAAC,SAAqC;AACpE,QAAM,QAAQ;AACd,QAAM,QAAQ,KAAK,MAAM,KAAK;AAE9B,MAAI,CAAC,OAAO;AAEX,UAAM,cAAc;AACpB,UAAM,cAAc,KAAK,MAAM,WAAW;AAE1C,QAAI,aAAa;AAChB,YAAM,GAAGA,YAAAA,EAAaC,QAAOC,QAAO,IAAI;AACxC,YAAM,eAAeA,YAAW;AAChC,aAAO;AAAA,QACN,WAAYF,eAAa,oBAAI,KAAA,GAAO,YAAA;AAAA,QACpC,OAAOC,UAAS;AAAA,QAChB,SAAS,aAAa,QAAQ,oBAAoB,EAAE;AAAA,QACpD,aAAa,kBAAkB,YAAY;AAAA,QAC3C,MAAM,CAAA;AAAA,MAAC;AAAA,IAET;AACA,WAAO;AAAA,MACN,YAAW,oBAAI,KAAA,GAAO,YAAA;AAAA,MACtB,OAAO;AAAA,MACP,SAAS,KAAK,QAAQ,oBAAoB,EAAE;AAAA,MAC5C,aAAa,kBAAkB,IAAI;AAAA,MACnC,MAAM,CAAA;AAAA,IAAC;AAAA,EAET;AAEA,QAAM,GAAG,WAAW,OAAO,WAAW,IAAI;AAC1C,MAAI,UAAU,YAAY,KAAA;AAC1B,MAAI,OAAkB,CAAA;AAEtB,QAAM,mBAAmB,QAAQ,YAAY,GAAG;AAChD,MAAI,mBAAmB,IAAI;AAC1B,UAAM,oBAAoB,QAAQ,UAAU,gBAAgB;AAC5D,QAAI;AACH,YAAM,aAAa,KAAK,MAAM,iBAAiB;AAC/C,UAAI,MAAM,QAAQ,UAAU,GAAG;AAC9B,eAAO;AACP,kBAAU,QAAQ,UAAU,GAAG,gBAAgB,EAAE,KAAA;AAAA,MAClD;AAAA,IACD,QAAQ;AAAA,IAER;AAAA,EACD;AAEA,SAAO;AAAA,IACN;AAAA,IACA;AAAA,IACA,SAAS,QAAQ,QAAQ,oBAAoB,EAAE;AAAA,IAC/C,aAAa,kBAAkB,OAAO;AAAA,IACtC;AAAA,EAAA;AAEF;AAQA,gBAAgB,iBAAiB,UAA0C;AAC1E,QAAM,aAAa,MAAM,KAAK,UAAU,GAAG;AAC3C,MAAI;AACH,UAAM,QAAQ,MAAM,WAAW,KAAA;AAC/B,UAAM,aAAa,KAAK;AACxB,UAAM,SAAS,OAAO,MAAM,UAAU;AACtC,QAAI,WAAW,MAAM;AACrB,QAAI,WAAW;AAEf,WAAO,WAAW,GAAG;AACpB,YAAM,WAAW,KAAK,IAAI,UAAU,UAAU;AAC9C,kBAAY;AAEZ,YAAM,WAAW,KAAK,QAAQ,GAAG,UAAU,QAAQ;AACnD,YAAM,QAAQ,OAAO,SAAS,SAAS,GAAG,QAAQ;AAClD,YAAM,SAAS,QAAQ,UAAU,MAAM,IAAI;AAI3C,iBAAW,MAAM,WAAW;AAG5B,eAAS,IAAI,MAAM,SAAS,GAAG,KAAK,GAAG,KAAK;AAC3C,YAAI,MAAM,CAAC,EAAE,OAAQ,OAAM,MAAM,CAAC;AAAA,MACnC;AAAA,IACD;AAEA,QAAI,SAAS,KAAA,EAAQ,OAAM;AAAA,EAC5B,UAAA;AACC,UAAM,WAAW,MAAA;AAAA,EAClB;AACD;AAOA,eAAe,sBAAsB,UAAkB,UAAsC;AAC5F,QAAM,QAAkB,CAAA;AACxB,MAAI,aAAoC,iBAAiB,QAAQ;AAEjE,MAAI,UAAU;AACb,iBAAa,WAAW,KAAK,wBAAwB;AAAA,EACtD,OAAO;AACN,iBAAa,WAAW,KAAK,cAAc;AAAA,EAC5C;AAEA,QAAM,KAAK,gBAAgB;AAAA,IAC1B,OAAO;AAAA,IACP,WAAW;AAAA,EAAA,CACX;AAED,mBAAiB,QAAQ,IAAI;AAC5B,QAAI,KAAK,KAAA,EAAQ,OAAM,KAAK,IAAI;AAAA,EACjC;AAGA,SAAO,MAAM,QAAA;AACd;AAEO,MAAM,MAAsB,OAAO,EAAE,QAAQ,UAAU;AAC7D,QAAM,EAAE,SAAS;AAEjB,MAAI;AACH,QAAI,CAAC,MAAM;AACV,YAAM,MAAM,KAAK,cAAc;AAAA,IAChC;AAEA,UAAM,SAAS,EAAE,MAAM,aAAa;AAAA,MACnC,OAAO,IAAI,aAAa,IAAI,OAAO,KAAK;AAAA,MACxC,QAAQ,IAAI,aAAa,IAAI,QAAQ,KAAK;AAAA,MAC1C,WAAW,IAAI,aAAa,IAAI,WAAW,KAAK;AAAA,MAChD,SAAS,IAAI,aAAa,IAAI,SAAS,KAAK;AAAA,MAC5C,MAAM,OAAO,IAAI,aAAa,IAAI,MAAM,CAAC,KAAK;AAAA,MAC9C,OAAO,OAAO,IAAI,aAAa,IAAI,OAAO,CAAC,KAAK;AAAA,IAAA,CAChD;AAED,UAAM,gBAAgB;AACtB,UAAM,gBAAgB;AACtB,UAAM,qBAAqB,UAAU,sBAAsB;AAE3D,UAAM,gBAAgB,OAAO,YAAY,IAAI,KAAK,OAAO,SAAS,EAAE,QAAA,IAAY;AAChF,UAAM,cAAc,OAAO,UAAU,IAAI,KAAK,IAAI,KAAK,OAAO,OAAO,EAAE,SAAS,IAAI,IAAI,IAAI,GAAG,CAAC,EAAE,YAAY;AAG9G,UAAM,cAAc,OAAO,OAAO,KAAK,OAAO;AAC9C,UAAM,aAAa,OAAO;AAC1B,UAAM,cAAc,aAAa;AAEjC,UAAM,gBAA+B,CAAA;AAGrC,UAAM,QAAQ,MAAM,QAAQ,aAAa;AACzC,UAAM,WAAW,MACf,OAAO,CAAC,SAAS,SAAS,iBAAiB,KAAK,WAAW,GAAG,aAAa,GAAG,CAAC,EAC/E,KAAK,CAAC,GAAG,MAAM;AAEf,UAAI,MAAM,cAAe,QAAO;AAChC,UAAI,MAAM,cAAe,QAAO;AAGhC,aAAO,EAAE,cAAc,CAAC;AAAA,IACzB,CAAC;AAIF,eAAW,QAAQ,UAAU;AAE5B,UAAI,cAAc,UAAU,YAAa;AAEzC,YAAM,WAAW,KAAK,eAAe,IAAI;AACzC,YAAM,YAAY,MAAM,KAAK,QAAQ;AAGrC,YAAM,eAAe,SAAS;AAC9B,UAAI,gBAAgB,UAAU,UAAU,KAAK,QAAQ,qBAAqB,KAAK,KAAK,KAAK,KAAM;AAC9F;AAAA,MACD;AAEA,YAAM,eAAe,KAAK,SAAS,KAAK,KAAK,KAAK,SAAS,KAAK;AAChE,YAAM,WAAW,KAAK,SAAS,KAAK;AAEpC,UAAI;AAEJ,UAAI,cAAc;AAEjB,yBAAiB,MAAM,sBAAsB,UAAU,QAAQ;AAAA,MAChE,OAAO;AAEN,yBAAiB,iBAAiB,QAAQ;AAAA,MAC3C;AAGA,uBAAiB,QAAQ,gBAAgB;AAExC,YAAI,cAAc,UAAU,YAAa;AAGzC,YAAI,OAAO,SAAS,SAAU;AAE9B,cAAM,QAAQ,uBAAuB,IAAI;AACzC,YAAI,CAAC,MAAO;AAEZ,cAAM,iBAAiB,IAAI,KAAK,MAAM,SAAS,EAAE,QAAA;AAOjD,YAAI,iBAAiB,cAAe;AACpC,YAAI,iBAAiB,YAAa;AAGlC,cAAM,aAAa,OAAO,UAAU,SAAS,MAAM,MAAM,YAAA,MAAkB,OAAO,MAAM,YAAA;AACxF,cAAM,YAAY,CAAC,OAAO,UAAU,MAAM,QAAQ,YAAA,EAAc,SAAS,OAAO,OAAO,YAAA,CAAa;AAEpG,YAAI,cAAc,WAAW;AAC5B,wBAAc,KAAK,KAAK;AAAA,QACzB;AAAA,MACD;AAAA,IACD;AAKA,UAAM,gBAAgB,cAAc,MAAM,YAAY,aAAa,UAAU;AAE7E,UAAM,gBAAgB,EAAE,MAAM,EAAE,MAAM,cAAc,GAAG,aAAa;AAEpE,WAAO,KAAK,4BAA4B;AAAA,MACvC,OAAO,cAAc;AAAA,MACrB,MAAM,OAAO;AAAA,MACb,aAAa,KAAK;AAAA,IAAA,CAClB;AAED,WAAO,KAAK;AAAA,MACX,MAAM;AAAA;AAAA;AAAA;AAAA;AAAA,MAKN,OAAO,cAAc;AAAA,MACrB,MAAM,OAAO;AAAA,MACb,OAAO,OAAO;AAAA;AAAA,MAEd,SAAS,cAAc,UAAU;AAAA,IAAA,CACjC;AAAA,EACF,SAAS,KAAK;AACb,QAAI,eAAe,EAAE,WAAW;AAC/B,YAAM,MAAM,KAAK,4BAA4B;AAAA,IAC9C;AACA,WAAO,MAAM,wBAAwB,GAAG;AACxC,UAAM,MAAM,KAAK,sBAAsB;AAAA,EACxC;AACD;"}